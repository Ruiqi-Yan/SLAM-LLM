{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import whisper\n",
    "from fuzzywuzzy import fuzz\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from word2number import w2n\n",
    "import inflect\n",
    "!export CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in jsonlines.Reader(f):\n",
    "            data.append(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_whisper(model_dir):\n",
    "    device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_dir, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_dir)\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device,\n",
    "    )\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path, pipe):\n",
    "    result = pipe([audio_path], batch_size=1)\n",
    "    return result[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_similarity(original_text, transcribed_text):\n",
    "    return fuzz.ratio(original_text.strip().lower(), transcribed_text.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = inflect.engine()\n",
    "def convert_numbers_to_words(text):\n",
    "    words = text[:-1].split()\n",
    "    result = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            result.append(p.number_to_words(word)) \n",
    "        else:\n",
    "            result.append(word)\n",
    "    \n",
    "    return ' '.join(result) + text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_inaccurate_data(data, dir, threshold=95):\n",
    "    filtered_data = []\n",
    "    pipe = set_whisper(\"/data/ruiqi.yan/models/whisper-large-v3/\")\n",
    "    for item in tqdm(data):\n",
    "        source_wav = os.path.join(dir, str(item['id']) + \".wav\")\n",
    "        source_text = convert_numbers_to_words(item['source_text'])\n",
    "\n",
    "        if os.path.exists(source_wav):\n",
    "            transcribed_text = convert_numbers_to_words(transcribe_audio(source_wav, pipe))\n",
    "            similarity = get_text_similarity(source_text, transcribed_text)\n",
    "\n",
    "            if similarity >= threshold:\n",
    "                filtered_data.append(item)\n",
    "        else:\n",
    "            print(f\"Warning: Audio file {str(item['id'])}.wav does not exist.\")\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_file, dir, similarity_threshold=95):\n",
    "    data = read_jsonl(input_file)\n",
    "    filtered_data = filter_inaccurate_data(data, dir, threshold=similarity_threshold)\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "  0%|          | 0/330 [00:00<?, ?it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "  3%|▎         | 10/330 [00:13<06:11,  1.16s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 330/330 [06:33<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "filtered_data = main(\"/data/ruiqi.yan/data/understanding/gk_listening/gk_test.jsonl\", \"/data/ruiqi.yan/data/eval/gaokao/gaokao\", similarity_threshold=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(\"/data/ruiqi.yan/data/understanding/gk_listening/gk_after_asr.jsonl\", mode='w') as writer:\n",
    "    for item in filtered_data:\n",
    "        writer.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yrq-omni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
